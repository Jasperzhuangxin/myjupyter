{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5354ed",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>GPT4<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#GPT-4核心技术有哪些？\" data-toc-modified-id=\"GPT-4核心技术有哪些？-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GPT-4核心技术有哪些？</a></span><ul class=\"toc-item\"><li><span><a href=\"#理论基础——多模态涌现能力\" data-toc-modified-id=\"理论基础——多模态涌现能力-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>理论基础——多模态涌现能力</a></span><ul class=\"toc-item\"><li><span><a href=\"#涌现能力（Emergent-Abilities）【量变引发质变】\" data-toc-modified-id=\"涌现能力（Emergent-Abilities）【量变引发质变】-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>涌现能力（Emergent Abilities）【量变引发质变】</a></span></li></ul></li><li><span><a href=\"#核心优势——多模态思维链\" data-toc-modified-id=\"核心优势——多模态思维链-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>核心优势——多模态思维链</a></span></li><li><span><a href=\"#编程范式——多模态提示工程\" data-toc-modified-id=\"编程范式——多模态提示工程-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>编程范式——多模态提示工程</a></span></li><li><span><a href=\"#关键技术——人类反馈强化学习\" data-toc-modified-id=\"关键技术——人类反馈强化学习-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>关键技术——人类反馈强化学习</a></span></li><li><span><a href=\"#安全技术——基于规则的奖励模型\" data-toc-modified-id=\"安全技术——基于规则的奖励模型-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>安全技术——基于规则的奖励模型</a></span></li><li><span><a href=\"#优化技术——近端策略优化（PPO）算法\" data-toc-modified-id=\"优化技术——近端策略优化（PPO）算法-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>优化技术——近端策略优化（PPO）算法</a></span></li><li><span><a href=\"#安全技术——多模态幻觉检测\" data-toc-modified-id=\"安全技术——多模态幻觉检测-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>安全技术——多模态幻觉检测</a></span></li><li><span><a href=\"#模型信息——关于模型大小\" data-toc-modified-id=\"模型信息——关于模型大小-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>模型信息——关于模型大小</a></span></li></ul></li><li><span><a href=\"#GPT-4的原理是什么？\" data-toc-modified-id=\"GPT-4的原理是什么？-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>GPT-4的原理是什么？</a></span><ul class=\"toc-item\"><li><span><a href=\"#从GPT-1到ChatGPT\" data-toc-modified-id=\"从GPT-1到ChatGPT-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>从GPT-1到ChatGPT</a></span></li><li><span><a href=\"#GPT-4的多模态架构\" data-toc-modified-id=\"GPT-4的多模态架构-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>GPT-4的多模态架构</a></span></li><li><span><a href=\"#GPT-4的独特性\" data-toc-modified-id=\"GPT-4的独特性-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>GPT-4的独特性</a></span></li></ul></li><li><span><a href=\"#GPT-4训练技术分析\" data-toc-modified-id=\"GPT-4训练技术分析-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>GPT-4训练技术分析</a></span><ul class=\"toc-item\"><li><span><a href=\"#GPT-4训练数据集\" data-toc-modified-id=\"GPT-4训练数据集-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>GPT-4训练数据集</a></span></li><li><span><a href=\"#GPT-4训练流程分析\" data-toc-modified-id=\"GPT-4训练流程分析-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>GPT-4训练流程分析</a></span><ul class=\"toc-item\"><li><span><a href=\"#第一阶段\" data-toc-modified-id=\"第一阶段-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>第一阶段</a></span></li><li><span><a href=\"#第二阶段\" data-toc-modified-id=\"第二阶段-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>第二阶段</a></span></li><li><span><a href=\"#第三阶段\" data-toc-modified-id=\"第三阶段-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>第三阶段</a></span></li><li><span><a href=\"#整个训练的核心\" data-toc-modified-id=\"整个训练的核心-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>整个训练的核心</a></span></li></ul></li><li><span><a href=\"#模型训练参数空间的早期筛选\" data-toc-modified-id=\"模型训练参数空间的早期筛选-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>模型训练参数空间的早期筛选</a></span></li><li><span><a href=\"#GPT-4的算力基座\" data-toc-modified-id=\"GPT-4的算力基座-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>GPT-4的算力基座</a></span></li></ul></li><li><span><a href=\"#GPT-4的算力基座\" data-toc-modified-id=\"GPT-4的算力基座-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>GPT-4的算力基座</a></span><ul class=\"toc-item\"><li><span><a href=\"#GPT-4计算服务器架构（按照计算芯片的组合方式）\" data-toc-modified-id=\"GPT-4计算服务器架构（按照计算芯片的组合方式）-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>GPT-4计算服务器架构（按照计算芯片的组合方式）</a></span><ul class=\"toc-item\"><li><span><a href=\"#计算服务器架构对比\" data-toc-modified-id=\"计算服务器架构对比-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>计算服务器架构对比</a></span><ul class=\"toc-item\"><li><span><a href=\"#CPU+GPGPU\" data-toc-modified-id=\"CPU+GPGPU-4.1.1.1\"><span class=\"toc-item-num\">4.1.1.1&nbsp;&nbsp;</span>CPU+GPGPU</a></span></li><li><span><a href=\"#CPU+DSA（TPU）\" data-toc-modified-id=\"CPU+DSA（TPU）-4.1.1.2\"><span class=\"toc-item-num\">4.1.1.2&nbsp;&nbsp;</span>CPU+DSA（TPU）</a></span></li><li><span><a href=\"#CPU+DSA+GPGPU\" data-toc-modified-id=\"CPU+DSA+GPGPU-4.1.1.3\"><span class=\"toc-item-num\">4.1.1.3&nbsp;&nbsp;</span>CPU+DSA+GPGPU</a></span></li></ul></li><li><span><a href=\"#计算卡间的高速互连\" data-toc-modified-id=\"计算卡间的高速互连-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>计算卡间的高速互连</a></span></li></ul></li><li><span><a href=\"#GPT-4计算相关芯片\" data-toc-modified-id=\"GPT-4计算相关芯片-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>GPT-4计算相关芯片</a></span></li></ul></li><li><span><a href=\"#GPT-4的局限与未来改进方向\" data-toc-modified-id=\"GPT-4的局限与未来改进方向-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>GPT-4的局限与未来改进方向</a></span><ul class=\"toc-item\"><li><span><a href=\"#GPT-4局限\" data-toc-modified-id=\"GPT-4局限-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>GPT-4局限</a></span></li><li><span><a href=\"#未来改进方向\" data-toc-modified-id=\"未来改进方向-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>未来改进方向</a></span><ul class=\"toc-item\"><li><span><a href=\"#RLAIF（Reinforcement-Learning-from-AI-Feedback）\" data-toc-modified-id=\"RLAIF（Reinforcement-Learning-from-AI-Feedback）-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>RLAIF（Reinforcement Learning from AI Feedback）</a></span></li><li><span><a href=\"#数理能力的增强\" data-toc-modified-id=\"数理能力的增强-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>数理能力的增强</a></span></li><li><span><a href=\"#GPT-4的本地化与小型化\" data-toc-modified-id=\"GPT-4的本地化与小型化-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>GPT-4的本地化与小型化</a></span></li></ul></li></ul></li><li><span><a href=\"#GPT-4的产业未来与投资机会\" data-toc-modified-id=\"GPT-4的产业未来与投资机会-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>GPT-4的产业未来与投资机会</a></span><ul class=\"toc-item\"><li><span><a href=\"#大模型的技术栈\" data-toc-modified-id=\"大模型的技术栈-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>大模型的技术栈</a></span></li><li><span><a href=\"#GPT-4的产业应用\" data-toc-modified-id=\"GPT-4的产业应用-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>GPT-4的产业应用</a></span></li><li><span><a href=\"#GPT-4对我们和未来的影响\" data-toc-modified-id=\"GPT-4对我们和未来的影响-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>GPT-4对我们和未来的影响</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f411d",
   "metadata": {},
   "source": [
    "# GPT-4核心技术有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abf4de",
   "metadata": {},
   "source": [
    "- 多模态大模型\n",
    "  - **多模态**：融合**文本**、**图像**、**视频**或**音频**等多种模态作为输入或输出\n",
    "  - 生成式预训练变换模型（Generative Pre-trained Transformer 4）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f63f57",
   "metadata": {},
   "source": [
    "## 理论基础——多模态涌现能力\n",
    "\n",
    "### 涌现能力（Emergent Abilities）【量变引发质变】\n",
    "- 模型具有从原始训练数据中**自动学习**并**发现新的、更高层次的特征和模式**的能力\n",
    "- 大语言模型（LLM）涌现出来的新能力\n",
    "- 多模态大语言模型（Multi-modal Large Language Model，MLLM）可实现更好的常识推理性能，跨模态迁移更有利于知识获取，产生更多新的能力，加速了能力的涌现\n",
    "- 涌现能力是基于深度学习模型的**分层结构**和**权重学习机制**实现的\n",
    "  - 每一层神经元（可视为变量组合）的输出都作为下一层神经元的输入\n",
    "  - 并且模型的每个权重（Weight）都通过强化学习算法进行学习和更新\n",
    "- 涌现能力的另一个重要表现是模型的**泛化能力**\n",
    "  - 在没有专门训练过的情况，GPT-4也可以泛化到新的、未知的多模态数据样本上\n",
    "  - 这种泛化能力取决于模型的结构和训练过程，以及数据的数量和多样性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd2cda",
   "metadata": {},
   "source": [
    "## 核心优势——多模态思维链\n",
    "- 模型通过学习**大量的语言数据**来构建一个**关于语言结构和意义**的内在表示，通过一系列**中间自然语言推理步骤**来完成最终输出\n",
    "- 思维链（Chain of Thought）可视为大语言模型涌现出来的核心能力之一\n",
    "- 思维链是ChatGPT和GPT-4能让大众感觉到语言模型“像人”的关键特性\n",
    "- 具备了多模态思维链能力的GPT-4模型具有一定**逻辑分析能力**\n",
    "- 通过**多模态思维链技术**，GPT-4将一个多步骤的问题分解为可以单独解决的中间步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1522e",
   "metadata": {},
   "source": [
    "## 编程范式——多模态提示工程\n",
    "- 多模态大模型（如GPT-4）的提示工程（Prompt Engineering）是指根据**特定的目标和语境**设计出**一系列问题或任务**，以便使用大模型**生成有关主题或主题领域**的**连贯和有意义**的文本\n",
    "- 目标是通过精心设计提示以从模型中引出所需的响应，来提高生成文本的质量和相关性\n",
    "- 提示工程与思维链的产生密不可分，也是目前自然语言编程的理论基础\n",
    "- 语言模型的研究重心在从传统特定领域的**有监督学习模式（基于非神经网络或神经网络）**转移到**预训练模型**上的过程中，**提示工程**成为了预训练模型的新方向\n",
    "- GPT-4/GPT-3模型中提示的新范式可归纳为“预训练+提示+预测”（Pre-train+Prompt+Predict）\n",
    "- GPT-4的提示工程涉及几个步骤，包括\n",
    "  - 选择合适的模型架构和参数\n",
    "  - 设计提示格式和结构\n",
    "  - 选择合适的任务和训练数据\n",
    "  - 使用选定的提示和数据微调模型\n",
    "- 提示工程同时也提高了语言模型“可操纵性”，即模型根据用户要求更改其行为的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede6570",
   "metadata": {},
   "source": [
    "## 关键技术——人类反馈强化学习\n",
    "- RLHF（Reinforcement Learning from Human Feedback，人类反馈强化学习）\n",
    "- OpenAI希望通过RLHF技术，模型能倾向出高质量回答，**确保模型输出对人类有益**，进而保证模型的安全性。\n",
    "- RLHF也是**保持多轮对话不偏离主题**的关键保障\n",
    "- TAMER（Training an Agent Manually via Evaluative Reinforcement，评估式强化人工训练代理）\n",
    "  - 将人类标记员引入到模型代理（Agents）的学习循环中，可以通过人类向代理提供**奖励反馈**（即指导Agents进行训练）\n",
    "  - 从而快速达到训练任务目标\n",
    "- GPT-4的多模态奖励模型（RM）是小号的有监督精调模型（SFT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e294e",
   "metadata": {},
   "source": [
    "## 安全技术——基于规则的奖励模型\n",
    "- 当给定不安全的输入时，模型可能会生成不良内容，例如提供有关犯罪的建议\n",
    "- 模型也可能对安全输入变得过于谨慎，拒绝无害的请求\n",
    "- GPT-4的安全流水线包括两个主要部分\n",
    "  - 一组额外的安全相关RLHF训练提示\n",
    "  - 基于规则的奖励模型（Rule-based Reward Model，RBRM）\n",
    "    - 是一组zero-shot迷你GPT-4分类器\n",
    "    - 根据预定义的规则为特定动作或事件分配奖励\n",
    "      - 奖励是根据事先定义的一组规则确定的，而不是从数据中学习得到的\n",
    "      - 规则奖励模型基于代理是否遵循特定规则或实现特定目标，为代理分配奖励"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fa659",
   "metadata": {},
   "source": [
    "## 优化技术——近端策略优化（PPO）算法\n",
    "- 近端策略优化（Proximal Policy Optimization，PPO）算法是一种高效的强化学习优化策略算法\n",
    "- PPO算法衍生于早期的策略梯度（Policy Gradient）算法\n",
    "- PPO算法采用两个神经网络来表示模型的策略\n",
    "  - 一个执行动作（Actor）\n",
    "  - 一个处理奖励（Critic）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec1114",
   "metadata": {},
   "source": [
    "## 安全技术——多模态幻觉检测\n",
    "- 幻觉（Hallucination）指的是模型生成的输出包含一些与输入不符合的信息，这些信息可能是错误的、无关的或者荒谬的\n",
    "- 大模型（包括GPT-4）本质上可以视为训练集（人类知识/语言）的**有损压缩**，模型的幻觉来自于**信息压缩的偏差**\n",
    "- 多模态**幻觉的本质**是这种**有损压缩偏差**的体现，也是通过数学逼近人类语言的必然代价\n",
    "- 幻觉包括以下几类\n",
    "  - 含义相关性（Semantic Relatedness）的幻觉\n",
    "  - 语义扩张（Semantic Expansion）的幻觉\n",
    "  - 结构错误（Structural Errors）的幻觉\n",
    "- 为了降低幻觉出现的概率，改善模型质量，Meta AI提出一种**幻觉内容检测机制**\n",
    "  - 通过检测生成内容中的**幻觉令牌/单词**，对生成内容的真实度进行评估，以减少模型幻觉出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9cc06",
   "metadata": {},
   "source": [
    "## 模型信息——关于模型大小\n",
    "- GPT-3是目前最大的知名语言模型之一，包含了1750亿（175B）个参数\n",
    "- GPT-3发布之前，微软的Turing NLG模型，大小为17亿（1.7B）个参数\n",
    "- 随着技术和算法的不断发展，GPT-4模型似乎也应朝着更大的尺寸发展\n",
    "- 有传言说GPT-4模型大概是GPT-3的100倍或1000倍\n",
    "- GPT-4的执行时间大概是GPT-3.5的3.7倍\n",
    "- 预计GPT-4的模型参数大概为62B-1500B之间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3b90b",
   "metadata": {},
   "source": [
    "# GPT-4的原理是什么？\n",
    "- 严格意义上的多模态模型，可以支持图像和文字两类信息的同时输入\n",
    "- 多模态输入的图像和文本基于Transformer作为通用接口\n",
    "  - **图形感知模块**与**语言模块**对接进行进一步计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f5983",
   "metadata": {},
   "source": [
    "## 从GPT-1到ChatGPT\n",
    "- GPT家族（GPT家族与BERT模型都是知名的NLP模型族，都基于Transformer技术）\n",
    "  - GPT-1（GPT-1只有12层）\n",
    "  - GPT-2\n",
    "  - GPT-3（GPT-3增加到96层）\n",
    "  - ChatGPT\n",
    "  - GPT-4（增加了额外的视觉语言模块，理论上具有更大的模型尺寸和输入窗口）\n",
    "- GPT和BERT之前的时代\n",
    "  - 最早的**NLP技术**是基于规则的，即基于特定的规则使用程序进行固定模式的对话，所有的应答都是固定模式的\n",
    "  - 在**深度学习**诞生后，**NLP技术**逐渐进入**基于模型**的时代\n",
    "    - 实现文本生成是通过\n",
    "      - 递归神经网络（RNN）\n",
    "      - 长短时记忆神经网络（LSTM）\n",
    "    - 这些模型\n",
    "      - 能够较好的进行模式识别，在输出单个单词或短语方面表现良好\n",
    "      - 但无法生成高精度的多轮对话，更无法实现逻辑推理能力\n",
    "- 2018年6月，OpenAI发表了GPT-1，GPT家族首次登上历史舞台\n",
    "  - GPT-1的核心是Transformer\n",
    "  - **Transformer**在数学上是**大矩阵的计算**\n",
    "    - 通过计算**不同语义**之间的**关联度**（**概率**）来生成具有**最高概率**的**语义反馈**\n",
    "- 2019年，OpenAI发表了另一篇关于他们最新模型GPT-2的论文\n",
    "  - 相对GPT-1，GPT-2是泛化能力更强的词向量模型\n",
    "    - **训练数据集**（WebText）和**模型参数量**更大\n",
    "  - 目前很多开源的GPT类模型是基于GPT-2进行的结构修改或优化\n",
    "- 2020年6月，OpenAI发表了另一篇关于GPT-3模型的论文\n",
    "  - 该模型的参数是GPT-2的100倍（175B）\n",
    "  - GPT-3实际上由多个版本组成的第3代家族，具有不同数量的参数和所需的计算资源\n",
    "    - 比如专门用于代码编程的code系列\n",
    "  - GPT-3的后继知名版本包括InstructGPT和ChatGPT\n",
    "- 2022年3月15日，OpenAI发布了名为“text-davinci-003”的新版GPT-3（GPT-3.5/ChatGPT）\n",
    "  - ChatGPT很可能是OpenAI在GPT-4正式推出之前的演练，或用于收集大量对话数据\n",
    "  - ChatGPT在对话过程中会**记忆先前使用者的对话讯息**，即**上下文理解**\n",
    "    - ChatGPT可实现连续对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f2617",
   "metadata": {},
   "source": [
    "## GPT-4的多模态架构\n",
    "- GPT-4，技术内涵产生的飞跃其实超过了ChatGPT\n",
    "  - 人类或其他高等生物的认知能力通常与从多种模式中学习有关\n",
    "- 从数学或从机器学习的角度来看，语言模型是对词语序列的概率相关性分布的建模\n",
    "  - 利用已经说过的语句（语句可以视为**数学中的向量**）作为**输入条件**\n",
    "  - 预测下一个时刻不同语句甚至语言集合出现的**概率分布**\n",
    "- GPT-4等模型新出现的**多模态输入**的能力对**语言模型**至关重要\n",
    "  - 使得**单纯的符号语义**扩展为更多的内涵\n",
    "    - 多模态感知（常识性知识）\n",
    "    - 感知与语义理解的结合\n",
    "    - 通过感知统一了接口\n",
    "- 常见的多模态大模型包括\n",
    "  - 图像描述生成或文本生成图像。例如最近知名的CLIP、Stable Diffusion\n",
    "  - 图文问答。例如带有图示的物理题求解或图表分析\n",
    "  - 文本到图像或图像到文本的检索\n",
    "  - 视频流描述\n",
    "- 目前常见的<font color=\"red\">**多模态模型架构**</font>\n",
    "  - 合并注意力架构（Merge-attention）\n",
    "    - 多个输入模态调整为**同一的特征表示**，多个模态的特征在自注意力之前被合并，共同进入Transformer\n",
    "  - 共同注意力架构（Co-attention）\n",
    "    - 每个输入模态都具备**私有自注意力通道**，用于模态独立特征的导入，然后再使用共同的**交叉注意力层**融合多模态特征\n",
    "  - 交叉注意力架构（Cross-attention）\n",
    "    - 对于多模态任务，将图像与语言分别结合，实现图文信息的**相互嵌入**与**问答**\n",
    "  - 三角Transformer架构（Tangled-transformer）\n",
    "    - 使用三组Transformer模块同时处理**动作**、**图形对象**和**语言特征**，\n",
    "    - 通过特定的三角连接关系，注入其他模态的Transformer网络，以不同模态的信息融合\n",
    "  - 模态间对比学习架构（Inter-Modality Contrastive Learning）\n",
    "    - 不同模态的信息被分解，通过**矩阵结构**建立多模态对比学习关联"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5ec6b",
   "metadata": {},
   "source": [
    "## GPT-4的独特性\n",
    "- GPT-4是最新且最先进的OpenAI多模态大模型\n",
    "- 优秀的**图文分析**和**逻辑推理**能力铸就了GPT-4的护城河"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73ea3f",
   "metadata": {},
   "source": [
    "# GPT-4训练技术分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab042c",
   "metadata": {},
   "source": [
    "## GPT-4训练数据集\n",
    "- GPT-4的训练数据集是基于GPT-3和GPT-3.5的训练数据集构建的，并在两者基础上增加了多模态数据集\n",
    "  - GPT-3.5的训练数据收集\n",
    "    - 数据集贡献来自一个由30-50名OpenAI员工组成的团队\n",
    "    - 另外从第三方网站雇佣了固定的大约50-100名固定的标注员\n",
    "    - GPT-3.5的数据集包括\n",
    "      - **SFT数据集**（SFT模型，Supervised Fine-Tuning，有监督策略精调，GPT模型精调）\n",
    "      - **RM数据集**（奖励模型（Reward Mode，RM））\n",
    "      - **PPO训练数据集**（Proximal Policy Optimization，近端策略优化）\n",
    "    - 极少量的高质量标注数据却显著提升了GPT-3.5的应答能力\n",
    "      - 好比好的教材胜过大量普通书籍\n",
    "  - 到了GPT-4又增加了大量多模态数据\n",
    "    - GPT-4的多模态训练数据集由图片和文本共同构成（一般是单幅图片+多行文本）\n",
    "    - 分析GPT-4的多模态数据集包括\n",
    "      - **图表推理**\n",
    "      - **物理考试**\n",
    "      - **图像理解**\n",
    "      - **论文总结**\n",
    "      - **漫画图文**等不同类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa071f",
   "metadata": {},
   "source": [
    "## GPT-4训练流程分析\n",
    "\n",
    "### 第一阶段\n",
    "- 构建**交叉注意力架构预训练模型**，收集数据并进行**有监督策略**精调\n",
    "- 此时的SFT模型在遵循指令/对话方面已经优于GPT-3.5，但对多模态的解答不一定符合人类偏好。\n",
    "\n",
    "### 第二阶段\n",
    "- 训练**奖励模型**（Reward Mode，RM）和**基于规则的奖励模型**（Rule-Based Reward Model，RBRM）\n",
    "- RM模型接受一个输入，给出评价回答质量的分数\n",
    "  - 对于一对训练数据，**调节参数**使得高质量回答的打分比低质量的打分要高\n",
    "\n",
    "### 第三阶段\n",
    "- 采用PPO（Proximal Policy Optimization，**近端策略优化**）**强化学习**来优化策略\n",
    "  - 将在线学习转化为离线学习\n",
    "  - 靠奖励打分来更新预训练模型参数\n",
    "  - 把回报分数依次传递，由此产生**策略梯度**，通过**强化学习**的方式以**更新PPO模型参数**\n",
    "  - 不断重复第二和第三阶段，通过迭代，会训练出更高质量的GPT-4模型\n",
    "\n",
    "### 整个训练的核心\n",
    "- 在于\n",
    "  - 高质量数据集/Prompt的构建\n",
    "  - 思维链的训练技术\n",
    "  - 大算力工程能力\n",
    "  - 早期训练空间的预测和优选\n",
    "- 数据量反而不那么重要  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542d7d1",
   "metadata": {},
   "source": [
    "## 模型训练参数空间的早期筛选\n",
    "- 一种技术\n",
    "  - 降低训练量\n",
    "  - 节约大量购买服务器的经费\n",
    "- 当前语言模型领域的主流\n",
    "  - 大型预训练模型\n",
    "  - 少量高质量标注\n",
    "- 论文Scaling Laws for Neural Language Models (2020)\n",
    "  - 通过**三个要素**计算通过**交叉熵损失**预估GPT-4/GPT-3.5预训练模型**性能**（这三个因素与损失之间存在**幂律关系**）\n",
    "    - 模型参数数量\n",
    "    - 训练期间计算量\n",
    "    - 训练数据大小\n",
    "  - 增加10倍才能将损失减少一个单位\n",
    "  - 增加100倍才能将损失减少两个单位，依此类推\n",
    "- GPT-3等模型越来越大，是从**综合训练成本**考虑的\n",
    "- **缩放定律**不仅影响到模型的设计要素，也影响到基于**算力的训练策略**\n",
    "  - 缩放定律可以量化为公式L(C) = aCb+ c\n",
    "- OpenAI开发了针对性的算力基础设施和优化方法\n",
    "  - 在只使用大概千分之一的算力消耗时提前探索GPT-4训练的解空间\n",
    "  - 无需完全遍历所有可能的训练参数设置\n",
    "  - 投资人也可以提前预知自己投的创企大概能训练出多高精度的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619c218",
   "metadata": {},
   "source": [
    "## GPT-4的算力基座\n",
    "- 由GPT-4/ChatGPT及其下游需求\n",
    "  - 带动了大量的**模型设计**与**产业应用**需求\n",
    "  - 带动了从**服务器集群**到**大算力芯片**的海量计算需求\n",
    "- 对于GPT-4等大模型设计或应用企业，**算力的需求**体现在如下三个细分阶段\n",
    "  - GPT-4预训练与应用微调阶段\n",
    "    - 一般需要**超算级别**或**数十台服务器**来进行一个大模型的训练计算\n",
    "    - 计算以**大量矩阵计算和求解**为主\n",
    "  - GPT-4推理与部署阶段\n",
    "    - 相对训练来说，部署要求的算力较低，但是基数很大\n",
    "    - 对于大量**在线交互**来说，部署阶段的**服务器/芯片**成本要远远超过训练阶段\n",
    "    - 每台AI服务器可以部署一个GPT-4模型，集群上会有大量服务器进行并行的网络服务，计算以大量**矩阵计算**和**存储调度**为主\n",
    "    - 会有**硬件性价比**和**反应延迟**的特定要求，目前的**GPU就不一定适合**\n",
    "  - GPT-4模型迭代的微调阶段\n",
    "    - 每使用一段时间，就会根据使用者或者客户反馈，对模型进行调整，以提高客户满意度，特别是提升模型的安全度以确保合规\n",
    "    - 这个过程就是**模型迭代**的过程，一般相当于小规模的训练，**训练所用的数据规模不大**，计算以大量矩阵计算和求解为主"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83531b",
   "metadata": {},
   "source": [
    "# GPT-4的算力基座"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a8d1a",
   "metadata": {},
   "source": [
    "## GPT-4计算服务器架构（按照计算芯片的组合方式）\n",
    "\n",
    "### 计算服务器架构对比\n",
    "- CPU、GPGPU、DSA本质上是**处理器计算单元**从少到多，**通用型**从高到低的演进趋势的体现\n",
    "- DSA即**领域专用加速器**，是用于一些特定场景或算法族计算的**芯片级加速**\n",
    "  - 最早的GPU也属于DSA，也就是**图形加速**的DSA\n",
    "- 随着GPU逐渐演化，将非常小的CPU核心加入GPU形成GPGPU架构后，才具备了**通用化**的**计算能力**\n",
    "\n",
    "#### CPU+GPGPU\n",
    "- 典型代表：Azura（训练+部署）\n",
    "- 优点：通用型最强，技术成熟，适合训练\n",
    "- 不足：大规模部署成本高，单位成本性能最低\n",
    "\n",
    "#### CPU+DSA（TPU）\n",
    "- 典型代表：Google（部署）\n",
    "- 优点：性能最优，降本增效，极强性价比优势\n",
    "- 不足：生态成熟需要时间（**计算灵活性**稍低一点，但是**计算性能**和**成本**都非常明显优于CPU+GPGPU模式）\n",
    "\n",
    "#### CPU+DSA+GPGPU\n",
    "- 典型代表：Google（训练）\n",
    "- 优点：兼顾训练与部署，灵活性较好（充分提高了灵活性又明显降低了计算成本）\n",
    "- 不足：部署稍复杂（需要算法设计/部署人员有丰富的异构架构部署经验）\n",
    "\n",
    "### 计算卡间的高速互连\n",
    "- 对GPT-4计算的影响排在**单卡算力**之后\n",
    "- 对于多数GPU来说，由于一般需要多卡才能放下一个模型，因此整体的计算效率受限于**互连带宽**和**单卡有效算力密度**。\n",
    "  - **算力密度**大可以减少**互连交互**的**总数据量**\n",
    "- 计算服务器之间的高速互连通过Infiniband实现\n",
    "  - 大带宽的Infiniband一般通过光纤连接（使用SerDes技术）来减少损耗\n",
    "  - Infiniband网络基于“以应用程序为中心”的观点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25684cd",
   "metadata": {},
   "source": [
    "## GPT-4计算相关芯片\n",
    "- 对于GPT-4这类大模型来说，其部署需要大量的**大算力计算**、**存储**和**数据**交互芯片\n",
    "  - **AI计算**：算力>100TFLOPS的GPGPU或大算力AI芯片\n",
    "  - **CPU**：核数>8的CPU\n",
    "  - **存储**：内存/GDDR/HBM/NVMe\n",
    "  - **数据交互**：Infiniband卡\n",
    "- 从芯片/半导体的历史发展规律看，预计近几年可能会有**新的专用架构**大发展来填补这一需求\n",
    "  - 针对大模型的DSA\n",
    "  - 更接近于DSA的GPGPU\n",
    "- GPT-4大模型具有**数据量大**、**数据带宽要求高**、**算力要求高**的计算特点，且**算法相对单一**\n",
    "  - 具备存算一体结构的DSA可以很好的满足这些要求，并且具备比GPGPU更高的计算性能\n",
    "- 在GPT-4这类大模型训练中，一般需要使用**Infiniband**进行大算力**芯片间的协同工作**，整合海量芯片的算力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0ae6b",
   "metadata": {},
   "source": [
    "# GPT-4的局限与未来改进方向"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09e3b6",
   "metadata": {},
   "source": [
    "## GPT-4局限\n",
    "- GPT-4在其未经**大量语料**训练的某些领域缺乏“**人类常识**”和“**引申能力**”\n",
    "  - 大预言模型的安全性问题仍是横亘在其大规模商用上的拉路虎\n",
    "- GPT-4需要非常大量的算力（芯片）来支持其训练和部署\n",
    "  - GPT-4在应用时仍然需要大算力的服务器支持，这些服务器的成本是普通企业在大流量服务时无法承受的\n",
    "  - 对于私有化部署来说，还需等待更轻量型的模型或更高性价比的算力平台\n",
    "- GPT-4还没法在线的把新知识纳入其中\n",
    "  - 很容易由于新数据的引入而导致对原有知识的灾难性遗忘\n",
    "  - 缺乏检查的新的不良知识也可能导致模型本身的安全性问题\n",
    "  - GPT-4可能会继承从新数据中学到的偏见和不平等性\n",
    "\n",
    "- GPT-4仍然是黑盒模型\n",
    "  - OpenAI提供的文档报告称，GPT-4-launch的错误行为率为0.02%\n",
    "  - GPT-4-launch生成的文本在10000次完成中只有2次违反OpenAI的内容政策或用户偏好\n",
    "    - 但即便这2次违反依然可能导致OpenAI受到严重的法律诉讼\n",
    "\n",
    "- GPT-4仍存在社会和道德风险\n",
    "  - OpenAI的研究表明，GPT-4可以在许多领域与人类宣传员相媲美\n",
    "    - 可能被滥用于创建假新闻、宣传、垃圾邮件或有害内容\n",
    "    - 可能产生可能误导或伤害用户的事实错误或偏见\n",
    "\n",
    "- GPT-4仍存在幻觉和推理错误\n",
    "  - GPT-4仍然可能会产生有害的建议（尽管GPT-4更有可能拒绝回答）、错误代码或不准确的信息\n",
    "  - 因此，GPT-4暂不应该用于错误成本高的区域（比如医学手术）\n",
    "\n",
    "- GPT-4存在泄露隐私可能\n",
    "  - GPT-4可从各种内部许可和公开可用的数据源中学习，其中可能包括大量公开有效的个人信息\n",
    "  - GPT-4还可以聚合不同信息，将大量隐含信息关联挖掘出来形成有效的隐私信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa263f78",
   "metadata": {},
   "source": [
    "## 未来改进方向\n",
    "\n",
    "### RLAIF（Reinforcement Learning from AI Feedback）\n",
    "- 2020年底，OpenAI前研究副总裁Dario Amodei带着10名员工创办了一个人工智能公司Anthropic\n",
    "  - 2022年12月，发表论文《Constitutional AI: Harmlessness from AI Feedback》介绍人工智能模型Claude\n",
    "  - Claude和GPT-4都依赖于强化学习（RL）来训练偏好（Preference）模型\n",
    "  - Claude的CAI的**排序过程使用模型**（**而非人类**）对所有生成的输出结果提供一个初始排序结果\n",
    "    - 人工智能根据一套**法规**（**Constitution**）原则来评价回复内容\n",
    "    - 用**人工智能反馈**来代替人类对表达无害性的偏好（RLAIF）的好处是节约了大量人工标注的时间和资源，可以加速大模型的训练进程，并降低成本\n",
    "\n",
    "### 数理能力的增强\n",
    "- 计算机学家Stephen Wolfram创造了\n",
    "  - **Wolfram语言**\n",
    "  - **计算知识搜索引擎Wolfram|Alpha**\n",
    "  - 后台通过**Mathematica**实现\n",
    "- Wolfram|Alpha会用其**符号翻译能力**将从GPT-4获得的**自然语言表达**“翻译”为对应的**符号化计算语言**\n",
    "  - GPT-4不必生成计算代码，只需生成常规自然语言\n",
    "  - 然后使用Wolfram|Alpha翻译成精确的Wolfram Language\n",
    "  - 再由底层的Mathematica进行计算\n",
    "\n",
    "### GPT-4的本地化与小型化\n",
    "- 有三类**模型压缩**（**model compression**）**技术**可以降低模型的大小和成本\n",
    "  - 第一种方法是**量化**（quantization）\n",
    "    - 降低单个权重的数值表示的精度\n",
    "  - 第二种模型压缩方法是**剪枝**（pruning）\n",
    "    - 删除GPT-4的网络元素\n",
    "  - 第三种模型压缩方法是**稀疏化**\n",
    "    - 这种稀疏结构目前还仅仅是基于GPU架构实现的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a9db5",
   "metadata": {},
   "source": [
    "# GPT-4的产业未来与投资机会"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef04513",
   "metadata": {},
   "source": [
    "## 大模型的技术栈\n",
    "- GPT-4这类大模型的用户量巨大，算力需求巨大，连接的设备和软件众多\n",
    "- 技术栈具有更多组件，可包括的工具\n",
    "  - 容器化\n",
    "  - 性能监控\n",
    "  - 商业智能\n",
    "  - 事件处理\n",
    "  - 云服务\n",
    "  - 微服务\n",
    "  - 分析\n",
    "- GPT-4/ChatGPT等大模型的技术栈可以分为5层\n",
    "  - 应用层\n",
    "    - 将生成的AI模型（可通过接口）集成到面向用户的应用程序，运行**私有模型**或通过**第三方接口运行模型**\n",
    "  - 接口层\n",
    "    - 包括各种调用API和数据中心调用工具，同时提供对应的提示工程接口和模型精调接口\n",
    "    - **接口层**将**应用层**和**模型层**衔接，方便应用层调用\n",
    "    - 实现以编程方式与模型进行交互\n",
    "  - 模型层\n",
    "    - 包括各类开源或非开源模型，以及各种模型的共享平台\n",
    "    - 这一层提供了不同的**模型数据**和**功能**\n",
    "  - 框架层\n",
    "    - 提供训练或云部署的**深度学习框架**和**中间件**等，包括**PyTorch**、**TensorFlow**等知名深度学习框架和中间件\n",
    "  - 计算层\n",
    "    - 为模型层提供模型计算和调度的各种**算力支持**，为训练AI模型运行训练和运行推理任务提供**基础设施**\n",
    "    - 计算层包括了各种**云计算平台**和**计算芯片**\n",
    "    - 在这一层，**AI芯片**会是核心瓶颈\n",
    "      - 在GPU替代CPU成为主要的AI算力芯片之后，AI界10多年来再一次受到大规模计算能力的限制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c83f2a",
   "metadata": {},
   "source": [
    "## GPT-4的产业应用\n",
    "- AIGC即利用人工智能技术来生成内容\n",
    "  - 与Web1.0、Web2.0时代的UGC、PGC比较\n",
    "    - UGC（用户生产内容）\n",
    "    - PGC（专业生产内容）\n",
    "  - AIGC是新一轮**内容生产方式**变革，而且AIGC内容在Web3.0时代也将出现**指数级增长**\n",
    "  - GPT-4模型的出现对于**图像/文字/语音多模态**的AIGC应用具有重要意义，会对AI产业上下游产生重大影响\n",
    "- 可以快速使用GPT-4的一些行业包括（可视为会快速变革的行业的预测）\n",
    "  - 教育行业\n",
    "  - 文娱行业\n",
    "  - 商业\n",
    "  - 新闻\n",
    "  - 医疗大健康\n",
    "  - 法律\n",
    "  - 生命科学\n",
    "    - GPT-4及其模型的**生物分支**可用于\n",
    "      - 从用于**临床试验**的**合成数据创建**\n",
    "      - 到基于**蛋白质折叠模型**的**生成式蛋白质设计**以加速药物发现\n",
    "      - 再到学术论文的研究总结\n",
    "      - 虽然采用还处于早期阶段，但**加速药物发现**和批准、改善患者疗效和节省医疗成本的潜力是巨大的\n",
    "  - 供应链和物流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef13f28",
   "metadata": {},
   "source": [
    "## GPT-4对我们和未来的影响\n",
    "- GPT-4会极大的影响宣传和社交\n",
    "- AI大量替代低端重复性沟通和多模态工作\n",
    "  - 更多的人借助GPT-4这类技术获得更高的效率并成为**自然语言程序员**\n",
    "  - **创造力**和**自然情感**成为人类能坚守的宝贵特质\n",
    "- 各种考核将从**知识型考核**转向**综合能力考核**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "GPT4",
   "title_sidebar": "GPT4",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.42px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
